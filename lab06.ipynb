{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "documentary-breakdown",
   "metadata": {},
   "source": [
    "# CSC311 Lab 6: Music Generation with a Multi-Layer Perceptron\n",
    "\n",
    "In this lab, we will build a simple multi-layer perceptron to predict the next\n",
    "note in a piece of classical music given the previous 20 notes.\n",
    "Though limited, this model can be used repeatedly as a rudimentary\n",
    "way to generate music.\n",
    "\n",
    "This is by no means the best method for music generation. In CSC413 we will cover\n",
    "Recurrent Neural Networks (RNN), which makes it possible for a model to \"remember\"\n",
    "past more than a previous set number of notes. In CSC413, we will also study \n",
    "Transformers, an even more powerful architecture that is currently the state of the art\n",
    "for natural language tasks.\n",
    "\n",
    "By the end of this tutorial, you will be able to:\n",
    "\n",
    "1. Implement a two-layer neural network with fully-connected layers (MLP) in `numpy`\n",
    "2. Vectorize the neural network forward pass to compute predictions for a batch of data.\n",
    "3. Vectorize the backpropagation computation to compute gradients updates for a two-layer MLP.\n",
    "4. Apply gradient descent to minimize the loss function of a MLP.\n",
    "5. Explain the limitation of a simple MLP model architectures for a complex task like music generation.\n",
    "\n",
    "Please work in groups of 1-2 during the tutorial.\n",
    "\n",
    "Acknowledgements:\n",
    "\n",
    "- Data is from https://www.kaggle.com/datasets/soumikrakshit/classical-music-midi\n",
    "\n",
    "## Submission\n",
    "\n",
    "If you are working with a partner, start by creating a group on Markus. If you are working alone,\n",
    "click \"Working Alone\".\n",
    "\n",
    "Submit the ipynb file `lab06.ipynb` on Markus \n",
    "**containing all your solutions to the Graded Task**s.\n",
    "Your notebook file must contain your code **and outputs** where applicable,\n",
    "including printed lines and images.\n",
    "Your TA will not run your code for the purpose of grading.\n",
    "\n",
    "For this lab, you should submit the following:\n",
    "\n",
    "- Part 2. Your implementation of the `softmax` function (1 point)\n",
    "- Part 2. Your annotations of the shapes of each forward- and backward-pass quantity (1 point)\n",
    "- Part 2. Your implementation of the `do_forward_pass` function (2 points)\n",
    "- Part 2. Your implementation of the `generate_piece` function (1 point)\n",
    "- Part 3. Your implementation of the `do_backward_pass` function (3 points)\n",
    "- Part 4. Your training curve on a single batch of data (1 point)\n",
    "- Part 6. Your discussion of the limitations of this architecture (1 point)\n",
    "\n",
    "You may produce a PDF document by exploring the Colab document, but be careful to check\n",
    "that the required code and output is not cut off.\n",
    "This method is preferred, since we would be able to more easily help point out issues.\n",
    "\n",
    "Alternatively, you may create a PDF document that contain the parts that are graded.\n",
    "However, the feedback we are able to provide may be more limited.\n",
    "\n",
    "## Google Colab Setup\n",
    "\n",
    "Since we will be working with music data, you will need to install a few libraries\n",
    "to be able to read and write midi files. Recall that on Google Colab, we use \n",
    "\"!\" to run shell commands.\n",
    "Below, we use such commands to install a few Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reading and writing midi files\n",
    "!pip install mido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complex-fisher",
   "metadata": {},
   "source": [
    "We will install a few more packages to write the `play_midi` function, which will play a midi file directly on Google Colab.\n",
    "You do not need these packages to complete the lab, only to play the training and generated midi files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-treatment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For playing midi files on Google Colab\n",
    "!apt install fluidsynth\n",
    "!cp /usr/share/sounds/sf2/FluidR3_GM.sf2 ./font.sf2\n",
    "!pip install midi2audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-interval",
   "metadata": {},
   "outputs": [],
   "source": [
    "from midi2audio import FluidSynth\n",
    "from IPython.display import Audio\n",
    "\n",
    "def play_midi(midi_filename):\n",
    "    \"\"\"Call `play_midi` with a path to a midi file will show a midi player on Google Colab.\"\"\"\n",
    "    FluidSynth(\"font.sf2\").midi_to_audio(midi_filename, 'test.wav')\n",
    "    return Audio(\"test.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-graduation",
   "metadata": {},
   "source": [
    "And let's not forget our trusty numpy and other useful imports!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-swing",
   "metadata": {},
   "source": [
    "## Part 1. Data\n",
    "\n",
    "As always, we need to download our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-charles",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download tutorial data files.\n",
    "!wget https://www.cs.toronto.edu/~lczhang/311/lab06/data.zip\n",
    "\n",
    "# Unzip the zip file.\n",
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-advancement",
   "metadata": {},
   "source": [
    "This data set consists of midi files of piano pieces composed by two classical\n",
    "composers: Chopin and Debussy. Musicians in this course will find that the pieces\n",
    "have been grossly simplified: each note has been changed to have the same loudness\n",
    "and duration. This is so that each piece of music can be represented as a sequence\n",
    "of notes in a straightforward way.\n",
    "\n",
    "As an example, let's play the simplified rendition of one of Chopin's pieces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_midi('data/chopin/chpn-p1_simplified.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polar-western",
   "metadata": {},
   "source": [
    "Compared to the original, non-simplified version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-bookmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_midi('data/chopin/chpn-p1.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-police",
   "metadata": {},
   "source": [
    "Just like with images, our computer represents music as a sequence of numbers.\n",
    "We represent each piece of music as a sequence of **notes**.\n",
    "In a midi file, each note's pitch is represented using an integer from 0-127.\n",
    "You can think of each note (e.g. each key on a piano) as having a unique integer identifier.\n",
    "The larger the integer identifier, the higher the pitch.\n",
    "\n",
    "For folks who happen to know a bit about musical notes, the identifier 60 represents the middle C:\n",
    "\n",
    "![](https://www.audiolabs-erlangen.de/resources/MIR/FMP/data/C1/FMP_C1_MIDI-NoteNumbers.png)\n",
    "\n",
    "The function for extracting the notes from a midi file is written for you. The\n",
    "file `get_midi_file_notes` takes a `.midi` filename and returns the sequence of\n",
    "notes in that file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mido import MidiFile, MidiTrack\n",
    "\n",
    "def get_midi_file_notes(filename):\n",
    "    \"\"\"Returns the sequence of notes played in the midi file\n",
    "    There are 128 possible notes on a MIDI device, and they are numbered 0 to 127.\n",
    "    The middle C is note number 60. Larger numbers indiciate higher pitch notes,\n",
    "    and lower numbers indicate lower pitch notes.\n",
    "\n",
    "    You can read more about the midi representation below, but it is not\n",
    "    necessary for this assignment.\n",
    "    http://midi.teragonaudio.com/tech/midispec/noteon.htm\n",
    "    \"\"\"\n",
    "    notes = []\n",
    "    for msg in  MidiFile(filename):\n",
    "        if msg.type == 'note_on':\n",
    "            notes.append(msg.note)\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-pastor",
   "metadata": {},
   "source": [
    "**Task**: Run the code below to print the sequence of notes for these two files.\n",
    "Explain why the two output sequences have **different** lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_midi_file_notes('data/chopin/chpn-p1_simplified.mid'))\n",
    "print(get_midi_file_notes('data/chopin/chpn-p2_simplified.mid'))\n",
    "\n",
    "# TODO: Write your explanation here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-economy",
   "metadata": {},
   "source": [
    "Now that we have represented a piece of music as a sequence of notes, we can\n",
    "begin generating our labelled data. We would like to predict the\n",
    "next note in a piece of classical music given the previous 20. To be able to\n",
    "train a neural network to perform such a task, we would need labelled data\n",
    "of the form:\n",
    "\n",
    "- Input $\\bf{x}$: A sequence of 20 notes in the piece of music.\n",
    "- Output $t$: The next note in the piece of music.\n",
    "\n",
    "The sequence of 20 notes is sometimes called the *context* used to predict the next note.\n",
    "The length of this sequence is called the *context length*.\n",
    "We will treat this number as a constant, but write our code to make it easy to experiment\n",
    "with other context lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-world",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_LENGTH = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-interaction",
   "metadata": {},
   "source": [
    "To create labelled data in this form, we'll iterate over a musical piece, and generate\n",
    "all possible data points $(\\bf{x}, t)$ of the previous 20 notes and the corresponding following note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-humor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_input_output(notes, context_length=CONTEXT_LENGTH):\n",
    "    \"\"\"\n",
    "    Generate a list of training data points, each of the form (x, t),\n",
    "    where \"x\" is a list of length `context_length` consisting of the\n",
    "    previous notes, and \"t\" is the corresponding next note.\n",
    "\n",
    "    Parameters:\n",
    "        `notes` - a sequence of notes in a piece, generated\n",
    "                  from calling `get_midi_file_notes`\n",
    "        `context_length` - length of each context\n",
    "\n",
    "    Returns: a list of training pairs (x, t), with len(x) == context_length\n",
    "    \"\"\"\n",
    "    D = []\n",
    "    for i in range(len(notes) - context_length):\n",
    "        seq = notes[i:i+context_length]\n",
    "        next_note = notes[i+context_length]\n",
    "        D.append((seq, next_note),)\n",
    "    \n",
    "    D.append((notes[-context_length:], 0),)\n",
    "    # Since the note 0 never appears in any of our pieces,\n",
    "    # we use note 0 to denote END OF SONG. In general, we choose\n",
    "    # a special value to denote the END OF SONG (usually a new\n",
    "    # category that doesn't match an actual note), so that our\n",
    "    # model might learn to end a song.\n",
    "    return D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-sample",
   "metadata": {},
   "source": [
    "**Task** To test the function `gen_input_output`, construct the training pairs for a single musical piece by Chopin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-donor",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_chpnop23 = get_midi_file_notes('data/chopin/chpn_op23_simplified.mid')\n",
    "\n",
    "D_chpnop23 = None # TODO\n",
    "\n",
    "# Since we are taking all possible subsequences of length (CONTEXT_LENGTH + 1)\n",
    "# of the sequence `notes`, the following two values should be the same\n",
    "print(len(notes_chpnop23))\n",
    "print(len(D_chpnop23) + CONTEXT_LENGTH - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-press",
   "metadata": {},
   "source": [
    "It may appear that we have our inputs and targets formatted appropriately.\n",
    "However, although notes have an ordering to them, they are actually more like categorical features than numeric ones.\n",
    "Treating notes as categorical values will help our model detect more patterns independent to their pitch.\n",
    "\n",
    "To that end, we will create indicator variables for each of these notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_onehot(indicies, total=128):\n",
    "    \"\"\"\n",
    "    Convert indicies into one-hot vectors by\n",
    "    first creating an identity matrix of shape [total, total],\n",
    "    then indexing the appropriate columns of that identity matrix.\n",
    "\n",
    "    Parameters:\n",
    "        `indices` - a numpy array of some shape where \n",
    "                    the value in these arrays should correspond to category\n",
    "                    indices (e.g. note values between 0-127)\n",
    "        `total` - the total number of categories (e.g. total number of notes)\n",
    "\n",
    "    Returns: a numpy array of one-hot vectors\n",
    "        If the `indices` array is shaped (N,)\n",
    "           then the returned array will be shaped (N, total)\n",
    "        If the `indices` array is shaped (N, D)\n",
    "           then the returned array will be shaped (N, D, total)\n",
    "        ... and so on.\n",
    "    \"\"\"\n",
    "    I = np.eye(total)\n",
    "    return I[indicies]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-computer",
   "metadata": {},
   "source": [
    "**Task**:\n",
    "Now that we have these functions,\n",
    "generate a small training data set from that one Chopin piece from earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-ready",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_t(D):\n",
    "    \"\"\"\n",
    "    Generate the data matrix \"X\" and target vector \"t\" from a data set \"D\",\n",
    "\n",
    "    Parameters:\n",
    "        `D` - a list of pairs of the form (x, t), returned from\n",
    "              the function `gen_input_output`\n",
    "\n",
    "    Returns: a tuple (X, t) where\n",
    "        `X` - a numpy array of shape (N, D), the data matrix\n",
    "        `t` - a numpy array of shape (N,),\n",
    "              with each value representing the index of the target note\n",
    "    \"\"\"\n",
    "    t = np.array([next_note for seq, next_note in D])\n",
    "    X_ids = np.array([seq for seq, next_note in D])\n",
    "    X = make_onehot(X_ids)\n",
    "    X = X.reshape(X.shape[0], -1)\n",
    "    return X,t \n",
    "\n",
    "X_chpnop23, t_chpnop23 = None, None # TODO - generate a data matrix and target vector from D_chpnop23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-hartford",
   "metadata": {},
   "source": [
    "You should see that the shape of X_chpnop23 is (5009, 2560). This is because a single notes sequence vector with shape (20,) must first get 1-hot encoded, making the new shape (20, 128). We then horizontally stack the 1-hot vectors into a single vector of shape (2560,) which is what np.reshape() does in the above function.\n",
    "\n",
    "This above data set only contains information about a single musical piece, rather than\n",
    "from all Chopin pieces in our data set. However, starting with a small data set will\n",
    "help us while we build and debug our model in Part 4.\n",
    "We will move on to use the full data set in Part 5.\n",
    "\n",
    "## Part 2. Model Building: Forward Pass\n",
    "\n",
    "In this section, we will build our 2-layer MLP machine learning model. We will start by writing the important softmax helper function, and then move on to writing the forward pass of the MLP.\n",
    "We will write the backward-pass and train the model in Part 3 and 4. \n",
    "But before then, we can test the forward pass of our model by evaluating an\n",
    "untrained MLP model.\n",
    "\n",
    "**Graded Task** Complete the function `softmax`. For numerical stability, instead of \n",
    "computing\n",
    "$y_k = \\frac{e^{z_k}}{\\sum_{l} e^{z_l}}$, we will instead take\n",
    "$m = \\max_l z_l$ and compute:\n",
    "$y_k = \\frac{e^{(z_k-m)}}{\\sum_{l} e^{(z_l-m)}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    \"\"\"\n",
    "    Compute the softmax of vector z, or row-wise for a matrix z.\n",
    "    For numerical stability, subtract the maximum logit value from each\n",
    "    row prior to exponentiation (see above).\n",
    "\n",
    "    Parameters:\n",
    "        `z` - a numpy array of shape (K,) or (N, K)\n",
    "\n",
    "    Returns: a numpy array with the same shape as `z`, with the softmax\n",
    "        activation applied to each row of `z`\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-speaking",
   "metadata": {},
   "source": [
    "Now we are ready to implement the MLP model. Mathematically, here is how our\n",
    "model will produce a prediction given a single input ${\\bf x}$:\n",
    "\\begin{align*}\n",
    "{\\bf m} &=  W^{(1)}{\\bf x} + {\\bf b}^{(1)} \\\\\n",
    "{\\bf h} &= \\textrm{ReLU}({\\bf m}) \\\\\n",
    "{\\bf z} &=  W^{(2)}{\\bf h} + {\\bf b}^{(2)} \\\\\n",
    "{\\bf y} &= \\textrm{softmax}({\\bf z})\n",
    "\\end{align*}\n",
    "\n",
    "The class `MLPModel` represents our 2-layer MLP. This class stores the weights\n",
    "and biases of our model. Moreover, this class will also have methods that\n",
    "use and modify these weights.\n",
    "\n",
    "Most of the class has been implemented for you, including these methods:\n",
    "\n",
    "- The `initializeParams()` method, which randomly initializes the weights\n",
    "- The `loss()` method, which computes the average cross-entropy loss\n",
    "- The `update()` method, which performs the gradient updates\n",
    "- The `cleanup()` method, which clears the member variables used in the computation\n",
    "\n",
    "The implementation for these methods are incomplete:\n",
    "\n",
    "- The `forward` method computes the prediction given a data matrix `X`.\n",
    "  These computations are known as the **forward pass**.\n",
    "  This method also saves some of the intermediate values in the neural network\n",
    "  computation, to make gradient computation easier.\n",
    "- The `backward` method computes the gradient of the average loss\n",
    "  with respect to various quantities (i.e. the error signals).\n",
    "  These computations are known as the **backward pass**.\n",
    "\n",
    "You may assume that during an iteration of gradient descent, the following methods\n",
    "will be called in order:\n",
    "\n",
    "- The `cleanup` method to clear information stored from the previous computation\n",
    "- The `forward` method to compute the predictions\n",
    "- The `backward` method to compute the error signals\n",
    "- (Possibly the `loss` method to compute the average loss)\n",
    "- The `update` method to move the weights\n",
    "\n",
    "This way of setting up the class methods might look strange, but is done \n",
    "so that our class methods become similar to that of PyTorch, which you will\n",
    "(probably) use in CSC413."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-enlargement",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel(object):\n",
    "    def __init__(self, num_features=128*20, num_hidden=100, num_classes=128):\n",
    "        \"\"\"\n",
    "        Initialize the weights and biases of this two-layer MLP.\n",
    "        \"\"\"\n",
    "        # information about the model architecture\n",
    "        self.num_features = num_features\n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # weights and biases for the first layer of the MLP\n",
    "        self.W1 = np.zeros([num_hidden, num_features])\n",
    "        self.b1 = np.zeros([num_hidden])\n",
    "\n",
    "        # weights and biases for the second layer of the MLP\n",
    "        self.W2 = np.zeros([num_classes, num_hidden])\n",
    "        self.b2 = np.zeros([num_classes])\n",
    "\n",
    "        # initialize the weights and biases\n",
    "        self.initializeParams()\n",
    "\n",
    "        # set all values of intermediate variables (to be used in the\n",
    "        # forward/backward passes) to None\n",
    "        self.cleanup()\n",
    "\n",
    "    def initializeParams(self):\n",
    "        \"\"\"\n",
    "        Initialize the weights and biases of this two-layer MLP to be random.\n",
    "        This random initialization is necessary to break the symmetry in the\n",
    "        gradient descent update for our hidden weights and biases. If all our\n",
    "        weights were initialized to the same value, then their gradients will\n",
    "        all be the same!\n",
    "        \"\"\"\n",
    "        self.W1 = np.random.normal(0, 2/self.num_features, self.W1.shape)\n",
    "        self.b1 = np.random.normal(0, 2/self.num_features, self.b1.shape)\n",
    "        self.W2 = np.random.normal(0, 2/self.num_hidden, self.W2.shape)\n",
    "        self.b2 = np.random.normal(0, 2/self.num_hidden, self.b2.shape)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Compute the forward pass to produce prediction for inputs.\n",
    "\n",
    "        Parameters:\n",
    "            `X` - A numpy array of shape (N, self.num_features)\n",
    "\n",
    "        Returns: A numpy array of predictions of shape (N, self.num_classes)\n",
    "        \"\"\"\n",
    "        return do_forward_pass(self, X) # To be implemented below\n",
    "\n",
    "    def backward(self, ts):\n",
    "        \"\"\"\n",
    "        Compute the backward pass, given the ground-truth, one-hot targets.\n",
    "\n",
    "        You may assume that the `forward()` method has been called for the\n",
    "        corresponding input `X`, so that the quantities computed in the\n",
    "        `forward()` method is accessible.\n",
    "\n",
    "        Parameters:\n",
    "            `ts` - A numpy array of shape (N, self.num_classes)\n",
    "        \"\"\"\n",
    "        return do_backward_pass(self, ts) # To be implemented below\n",
    "\n",
    "    def loss(self, ts):\n",
    "        \"\"\"\n",
    "        Compute the average cross-entropy loss, given the ground-truth, one-hot targets.\n",
    "\n",
    "        You may assume that the `forward()` method has been called for the\n",
    "        corresponding input `X`, so that the quantities computed in the\n",
    "        `forward()` method is accessible.\n",
    "\n",
    "        Parameters:\n",
    "            `ts` - A numpy array of shape (N, self.num_classes)\n",
    "        \"\"\"\n",
    "        return np.sum(-ts * np.log(self.y)) / ts.shape[0]\n",
    "\n",
    "    def update(self, alpha):\n",
    "        \"\"\"\n",
    "        Compute the gradient descent update for the parameters of this model.\n",
    "\n",
    "        Parameters:\n",
    "            `alpha` - A number representing the learning rate\n",
    "        \"\"\"\n",
    "        self.W1 = self.W1 - alpha * self.W1_bar\n",
    "        self.b1 = self.b1 - alpha * self.b1_bar\n",
    "        self.W2 = self.W2 - alpha * self.W2_bar\n",
    "        self.b2 = self.b2 - alpha * self.b2_bar\n",
    "\n",
    "    def cleanup(self):\n",
    "        \"\"\"\n",
    "        Erase the values of the variables that we use in our computation.\n",
    "        \"\"\"\n",
    "        # To be filled in during the forward pass\n",
    "        self.N = None # Number of data points in the batch\n",
    "        self.X = None # The input matrix\n",
    "        self.m = None # Pre-activation value of the hidden state, should have shape\n",
    "        self.h = None # Post-RELU value of the hidden state\n",
    "        self.z = None # The logit scores (pre-activation output values)\n",
    "        self.y = None # Class probabilities (post-activation)\n",
    "        # To be filled in during the backward pass\n",
    "        self.z_bar = None # The error signal for self.z2\n",
    "        self.W2_bar = None # The error signal for self.W2\n",
    "        self.b2_bar = None # The error signal for self.b2\n",
    "        self.h_bar = None  # The error signal for self.h\n",
    "        self.m_bar = None # The error signal for self.z1\n",
    "        self.W1_bar = None # The error signal for self.W1\n",
    "        self.b1_bar = None # The error signal for self.b1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-locator",
   "metadata": {},
   "source": [
    "**Graded Task**: For each of the following attributes of `MLPModel`,\n",
    "write down the shape of the quantity. A few of these are filled in for you.\n",
    "\n",
    "For the forward-pass quantities, consider the linear regression models that\n",
    "you built. You can determine the shapes of these quantities in the same way.\n",
    "\n",
    "For the backward-pass quantities, consider the relationship between the\n",
    "error signal of a quantity and the original quantity itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-prairie",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N      : integer\n",
    "# X      : shape (N, num_features)\n",
    "\n",
    "# m      : shape (N, num_hidden)\n",
    "# h      : TODO\n",
    "# z      : TODO\n",
    "# y      : TODO\n",
    "\n",
    "# z_bar  : TODO\n",
    "# W2_bar : TODO\n",
    "# b2_bar : TODO\n",
    "# h_bar  : TODO\n",
    "# m_bar  : shape (N, num_hidden) -- since it must have the same shape as m\n",
    "# W1_bar : TODO\n",
    "# b1_bar : TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-excitement",
   "metadata": {},
   "source": [
    "**Graded Task**: Complete the implementation of the `do_forward_pass` method,\n",
    "which computes the predictions given a `MLPModel` and a batch of input data.\n",
    "\n",
    "This requires vectorizing the equations from earlier to work with\n",
    "an entire *batch* of input data!\n",
    "We recommend that you reason about your approach on paper before writing any numpy code.\n",
    "Track the shapes of your quantities carefully. When you finally write your \n",
    "numpy code, print out the shapes of your quantities as you go along, and\n",
    "reason about whether these shapes match your initial expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-landscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_forward_pass(model, X):\n",
    "    \"\"\"\n",
    "    Compute the forward pass to produce prediction for inputs.\n",
    "\n",
    "    This function also keeps some of the intermediate values in\n",
    "    the neural network computation, to make computing gradients easier.\n",
    "\n",
    "    For the ReLU activation, you may find the function `np.maximum` helpful\n",
    "\n",
    "    Parameters:\n",
    "        `model` - An instance of the class MLPModel\n",
    "        `X` - A numpy array of shape (N, model.num_features)\n",
    "\n",
    "    Returns: A numpy array of predictions of shape (N, model.num_classes)\n",
    "    \"\"\"\n",
    "    model.N = X.shape[0]\n",
    "    model.X = X\n",
    "    model.m = None # TODO - the hidden state value (pre-activation)\n",
    "    model.h = None # TODO - the hidden state value (post ReLU activation)\n",
    "    model.z = None # TODO - the logit scores (pre-activation)\n",
    "    model.y = None # TODO - the class probabilities (post-activation)\n",
    "    return model.y\n",
    "\n",
    "# Here is a call to a forward pass operation to help you\n",
    "# test your code.\n",
    "test_mlp = MLPModel(num_features=10, num_hidden=20, num_classes=3)\n",
    "X = np.random.randn(8, 10)\n",
    "y = do_forward_pass(test_mlp, X)\n",
    "print(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-landing",
   "metadata": {},
   "source": [
    "**Graded Task**: Now that we are able to produce predictions, we can write a\n",
    "rudimentary function that uses a (to be trained) MLPModel generates music.\n",
    "Complete the function `generate_piece`, which generates a new piece of music\n",
    "using our model, one note at a time.\n",
    "\n",
    "To generate a next note, we use the previous 20 notes as input to the model.\n",
    "The model outputs a probability distribution over the next possible note, and we\n",
    "will take the most probable note as the next note in our piece.\n",
    "(Taking the most probable note is not the only approach, but is\n",
    "the simplest one that we will use in this course. You can imagine\n",
    "that we might instead want to sample from the output distribution\n",
    "or a related distribution.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-following",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_piece(model, seed, max_len=100):\n",
    "    \"\"\"\n",
    "    Generate a piece of music given the model and an initial\n",
    "    \"seed\" sequence of notes at the beginning of the piece.\n",
    "\n",
    "    The piece is generated one note at a time by using, as input\n",
    "    to the model, the previous 20 notes. The model outputs a \n",
    "    probability distribution over the next possible note, and we\n",
    "    will take the most probable note as the next note in our piece.\n",
    "\n",
    "    Parameters:\n",
    "        `model` - an instance of MLPModel\n",
    "        `seed` - a sequence of notes at the beginning of a piece,\n",
    "                 e.g. generated from calling `get_midi_file_notes`\n",
    "                 must be at least as long as CONTEXT_LENGTH\n",
    "        `max_len` - maximum number of total notes in the piece.\n",
    "\n",
    "    Returns: a list of sequence of notes with length at most `max_len`\n",
    "    \"\"\"\n",
    "    assert(len(seed) >= CONTEXT_LENGTH)\n",
    "\n",
    "    generated = seed # We use this to track the notes generated so far\n",
    "    while len(generated) < max_len:\n",
    "        # Use the model to predict the next note given the previous CONTEXT_LENGTH notes\n",
    "        last_n_notes = generated[-CONTEXT_LENGTH:]\n",
    "        # Think: What will we need to do to produce our input matrix\n",
    "        #        of shape (batch_size, model.num_features)?\n",
    "        #        You may wish to review the functions make_onehot() and\n",
    "        #        understand how it is used in get_X_t()\n",
    "        X = make_onehot(last_n_notes).reshape((1, -1))\n",
    "\n",
    "        y = None # Now, how can we use the model to produce a distribution over the possible notes?\n",
    "\n",
    "        next_note = None # Finally, how can we use the distribution to choose a single next note?\n",
    "\n",
    "        if next_note == 0: # Look for the marker for the end of the song\n",
    "            break\n",
    "        generated.append(next_note)\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-waterproof",
   "metadata": {},
   "source": [
    "One other helper function is written for you.\n",
    "This function converts a piece into a midi file,  so that we can play it right in Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-aberdeen",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_midi(notes, outfile):\n",
    "    from mido import MidiFile, MidiTrack, Message\n",
    "\n",
    "    new_mid = MidiFile()\n",
    "    new_track = MidiTrack()\n",
    "    new_mid.tracks.append(new_track)\n",
    "\n",
    "    for note in notes:\n",
    "        new_track.append(Message('note_on', note=note, velocity=64, time=128))\n",
    "    new_mid.save(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medical-future",
   "metadata": {},
   "source": [
    "**Task**: \n",
    "Run the below code to generate a piece of music using an **untrained** MLPModel(),\n",
    "starting from the first 20 notes from notes_chpnop23.\n",
    "Generate `CONTEXT_LENGTH` number of new notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = notes_chpnop23[:CONTEXT_LENGTH]\n",
    "notes = generate_piece(MLPModel(), seed, CONTEXT_LENGTH * 2)\n",
    "generate_midi(notes, 'chpnop23_untrained.mid')\n",
    "play_midi('chpnop23_untrained.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-drill",
   "metadata": {},
   "source": [
    "Compare the above MIDI with with just the seed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectacular-bracket",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = notes_chpnop23[:CONTEXT_LENGTH]\n",
    "generate_midi(seed, 'chpnop23_seed.mid')\n",
    "play_midi('chpnop23_seed.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-vampire",
   "metadata": {},
   "source": [
    "## Part 3. Model Building: Backwards Pass\n",
    "\n",
    "We are ready to complete the function that computes the backward pass of our model. \n",
    "\n",
    "You should start by reviewing the lecture slides on backpropagation.\n",
    "One difference between the slides and our implementation here is that the \n",
    "slides express the required computations for computing the gradients of\n",
    "the loss for a *single data point*.\n",
    "However, our implementation of backpropagation is further vectorized to\n",
    "compute gradients of the loss for a *batch consisting of multiple data points*.\n",
    "\n",
    "We begin with applying the backpropagation algorithm on our forward pass\n",
    "steps from earlier. Recall that our model's forward pass is as follows:\n",
    "\\begin{align*}\n",
    "{\\bf m} &=  W^{(1)}{\\bf x} + {\\bf b}^{(1)} \\\\\n",
    "{\\bf h} &= \\textrm{ReLU}({\\bf m}) \\\\\n",
    "{\\bf z} &=  W^{(2)}{\\bf h} + {\\bf b}^{(2)} \\\\\n",
    "{\\bf y} &= \\textrm{softmax}({\\bf z}) \\\\\n",
    "{\\mathcal L} &= {\\mathcal L}_{CE}({\\bf y}, {\\bf t})\n",
    "\\end{align*}\n",
    "\n",
    "Following the steps discussed in this week's lecture, we should get\n",
    "the following backward-pass computation (verify this yourself!):\n",
    "\\begin{align*}\n",
    "\\overline{{\\bf z}}  &= {\\bf y} - {\\bf t} \\\\\n",
    "\\overline{W^{(2)}}  &= \\overline{{\\bf z}}{\\bf h}^T \\\\\n",
    "\\overline{{\\bf b^{(2)}}}  &= \\overline{{\\bf z}} \\\\\n",
    "\\overline{{\\bf h}}  &= {W^{(2)}}^T\\overline{\\bf z} \\\\\n",
    "\\overline{{\\bf m}} &= \\overline{{\\bf h}} \\circ \\textrm{ReLU}'({\\bf m}) \\\\\n",
    "\\overline{W^{(1)}} &= \\overline{{\\bf m}} {\\bf x}^T \\\\\n",
    "\\overline{{\\bf b}^{(1)}} &= \\overline{{\\bf m}}\n",
    "\\end{align*}\n",
    "\n",
    "However, the computation is for a single input ${\\bf x}$.\n",
    "We will need to vectorize each of these computations.\n",
    "For some quantities, vectorizing the backward-pass computation is just as \n",
    "straightforward as the forward-pass computation, requiring the same\n",
    "techniques. For example, each \n",
    "input ${\\bf x}$ in a batch will have its own corresponding value of\n",
    "${\\bf z}$ and thus $\\overline{{\\bf z}}$. (If this sentence is confusing,\n",
    "check that your description of the shape for `z_bar` from Part 2 has the\n",
    "batch size `N` in there somewhere.)\n",
    "\n",
    "For other quantities, vectorizing requires the use of the multivariate chain rule.\n",
    "For example, there is a single weight matrix $W^{(2)}$, used for all\n",
    "inputs in a batch. Thus, a change in $W^{(2)}$ will affect the predictions for\n",
    "*all* inputs. (If this sentence is confusing,\n",
    "check that your description of the shape for `W2_bar` from Part 2 \n",
    "**does not** have batch size `N` in there.)\n",
    "\n",
    "Here are the results of vectorizing the computation across the\n",
    "data points. \n",
    "\n",
    "\\begin{align*}\n",
    "\\overline{{\\bf Z}}  &= \\frac{1}{N}({\\bf Y} - {\\bf T}) \\\\\n",
    "\\overline{W^{(2)}}  &= \\overline{{\\bf Z}}^T {\\bf H} \\\\\n",
    "\\overline{{\\bf b^{(2)}}}  &= \\mathbb{1}^T \\overline{{\\bf Z}} \\\\\n",
    "\\overline{{\\bf H}}  &= \\overline{\\bf Z} {W^{(2)}} \\\\\n",
    "\\overline{{\\bf M}} &= \\overline{{\\bf H}} \\circ \\textrm{ReLU}'({\\bf M}) \\\\\n",
    "\\overline{W^{(1)}} &=  \\overline{{\\bf M}}^T {\\bf X} \\\\\n",
    "\\overline{{\\bf b}^{(1)}} &= \\mathbb{1}^T \\overline{{\\bf M}}\n",
    "\\end{align*}\n",
    "\n",
    "Note that we are purposely skipping the \n",
    "computation of $\\overline{{\\bf Y}}$ and computing  \n",
    "$\\overline{{\\bf Z}}$ directly for numerical stability.\n",
    "\n",
    "**Graded Task**: Complete the implementation of the `do_backward_pass` function,\n",
    "which performs backpropagation given a `MLPModel`, given the ground-truth\n",
    "one-hot targets `ts`. This function assumes that the forward pass method had been \n",
    "called on the input `X` corresponding to those one-hot targets.\n",
    "\n",
    "Once again, we recommend that you reason about your approach on paper before\n",
    "writing any numpy code! In particular, understand the vectorization strategies\n",
    "discussed in the previous weeks and above before proceeding.\n",
    "Track the shapes of your quantities carefully! When you finally write your \n",
    "numpy code, print out the shapes of your quantities as you go along, and\n",
    "reason about whether these shapes match your initial expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-canyon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_backward_pass(model, ts):\n",
    "    \"\"\"\n",
    "    Compute the backward pass, given the ground-truth, one-hot targets.\n",
    "\n",
    "    You may assume that `model.forward()` has been called for the\n",
    "    corresponding input `X`, so that the quantities computed in the\n",
    "    `forward()` method is accessible.\n",
    "\n",
    "    The member variables you store here will be used in the `update()`\n",
    "    method. Check that the shapes match what you wrote in Part 2.\n",
    "\n",
    "    Parameters:\n",
    "        `model` - An instance of the class MLPModel\n",
    "        `ts` - A numpy array of shape (N, model.num_classes)\n",
    "    \"\"\"\n",
    "    model.z_bar = (model.y - ts) / model.N\n",
    "    model.W2_bar = None # TODO\n",
    "    model.b2_bar = None # TODO\n",
    "    model.h_bar = None # TODO\n",
    "    model.m_bar = None # TODO\n",
    "    model.W1_bar = None # TODO\n",
    "    model.b1_bar = None # TODO\n",
    "\n",
    "# Here is a call to a backward pass operation to help you\n",
    "# test your code.\n",
    "test_mlp = MLPModel(num_features=10, num_hidden=20, num_classes=3)\n",
    "X = np.random.randn(8, 10)\n",
    "ts = np.array([[1, 0, 0], \n",
    "               [1, 0, 0],\n",
    "               [1, 0, 0],\n",
    "               [0, 1, 0],\n",
    "               [0, 1, 0],\n",
    "               [0, 1, 0],\n",
    "               [0, 1, 0],\n",
    "               [0, 1, 1]])\n",
    "do_forward_pass(test_mlp, X)\n",
    "do_backward_pass(test_mlp, ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-baking",
   "metadata": {},
   "source": [
    "## Part 4. Memorizing One Song\n",
    "\n",
    "Neural networks are notoriously challenging to debug.\n",
    "So before we jump into actually training our model, it helps to verify that our model has been\n",
    "implemented correctly. \n",
    "Practitioners find it helpful to first check whether a model is capable of ``overfitting'' on a\n",
    "small data set: i.e. whether the model is capable of achieving a close to 0 loss relatively quickly\n",
    "on a very small training data (e.g. a single data point or a single mini-batch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-movie",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sgd(model, X_train, t_train,\n",
    "              alpha=0.1, n_epochs=0, batch_size=100,\n",
    "              X_valid=None, t_valid=None,\n",
    "              w_init=None, plot=True):\n",
    "    '''\n",
    "    Given `model` - an instance of MLPModel\n",
    "          `X_train` - the data matrix to use for training\n",
    "          `t_train` - the target vector to use for training\n",
    "          `alpha` - the learning rate.\n",
    "                    From our experiments, it appears that a larger learning rate\n",
    "                    is appropriate for this task.\n",
    "          `n_epochs` - the number of **epochs** of gradient descent to run\n",
    "          `batch_size` - the size of each mini batch\n",
    "          `X_valid` - the data matrix to use for validation (optional)\n",
    "          `t_valid` - the target vector to use for validation (optional)\n",
    "          `w_init` - the initial `w` vector (if `None`, use a vector of all zeros)\n",
    "          `plot` - whether to track statistics and plot the training curve\n",
    "\n",
    "    Solves for model weights via stochastic gradient descent,\n",
    "    using the provided batch_size.\n",
    "\n",
    "    Return weights after `niter` iterations.\n",
    "    '''\n",
    "    # as before, initialize all the weights to zeros\n",
    "    w = np.zeros(X_train.shape[1])\n",
    "    \n",
    "    train_loss = [] # for the current minibatch, tracked once per iteration\n",
    "    valid_loss = [] # for the entire validation data set, tracked once per epoch\n",
    "\n",
    "    # track the number of iterations\n",
    "    niter = 0\n",
    "\n",
    "    # we will use these indices to help shuffle X_train\n",
    "    N = X_train.shape[0] # number of training data points\n",
    "    indices = list(range(N))\n",
    "\n",
    "    for e in range(n_epochs):\n",
    "        random.shuffle(indices) # for creating new minibatches\n",
    "\n",
    "        for i in range(0, N, batch_size):\n",
    "            if (i + batch_size) > N:\n",
    "                # At the very end of an epoch, if there are not enough\n",
    "                # data points to form an entire batch, then skip this batch\n",
    "                continue\n",
    "\n",
    "            indices_in_batch = indices[i: i+batch_size]\n",
    "            X_minibatch = X_train[indices_in_batch, :]\n",
    "            t_minibatch = make_onehot(t_train[indices_in_batch], 128)\n",
    "\n",
    "            # gradient descent iteration\n",
    "            model.cleanup()\n",
    "            model.forward(X_minibatch)\n",
    "            model.backward(t_minibatch)\n",
    "            model.update(alpha)\n",
    "\n",
    "            if plot:\n",
    "                # Record the current training loss values\n",
    "                train_loss.append(model.loss(t_minibatch))\n",
    "            niter += 1\n",
    "\n",
    "        # compute validation data metrics, if provided, once per epoch\n",
    "        if plot and (X_valid is not None) and (t_valid is not None):\n",
    "            model.cleanup()\n",
    "            model.forward(X_valid)\n",
    "            valid_loss.append((niter, model.loss(make_onehot(t_valid))))\n",
    "\n",
    "    if plot:\n",
    "        plt.title(\"SGD Training Curve Showing Loss at each Iteration\")\n",
    "        plt.plot(train_loss, label=\"Training Loss\")\n",
    "        if (X_valid is not None) and (t_valid is not None): # compute validation data metrics, if provided\n",
    "            plt.plot([iter for (iter, loss) in valid_loss], \n",
    "                     [loss for (iter, loss) in valid_loss],                                \n",
    "                     label=\"Validation Loss\")\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        print(\"Final Training Loss:\", train_loss[-1])\n",
    "        if (X_valid is not None) and (t_valid is not None):\n",
    "            print(\"Final Validation Loss:\", valid_loss[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-donna",
   "metadata": {},
   "source": [
    "**Graded Task**: Show that your model in Part 2 is implemented correctly by running\n",
    "the below code and submitting your output to the TA.\n",
    "\n",
    "If you are not able to achieve close to 0 training loss quickly (~250 iterations),\n",
    "then you have some debugging to do. Here are some common issues to consider:\n",
    "\n",
    "- Does your code even run? If not, read the error carefully. There may be an issue\n",
    "  with your matrix compuation where the shapes of your quantities do not match.\n",
    "  If that's the case, it helps to print out the *shapes* of your numpy arrays\n",
    "  and analyze whether these shapes are what you expect them to be.\n",
    "- Are your gradients computed correctly? If your shapes are correct but your\n",
    "  gradients are not, your loss may not decrease. You might want to use the\n",
    "  finite difference method from lab 2 to check your gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce a single batch of data\n",
    "X_small = X_chpnop23[:100]\n",
    "t_small = t_chpnop23[:100]\n",
    "# your model should be able to achieve close to 0 training loss\n",
    "# i.e. within 500 iterations/epochs\n",
    "model = MLPModel()\n",
    "train_sgd(model, X_train=X_small, t_train=t_small, alpha=0.2, batch_size=100, n_epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-terrorism",
   "metadata": {},
   "source": [
    "## Part 5. Music Generation\n",
    "\n",
    "Now that you are reasonably sure that your model is implemented correctly, let's\n",
    "train a model on some of Chopin's pieces.\n",
    "\n",
    "There is still the question of splitting the training/validation/test data.\n",
    "This is actually a pretty nuanced questions.\n",
    "We would like to have a validation set to be able to detect and prevent overfitting.\n",
    "However, the way that we intend to use this model is unlike the models built in previous labs:\n",
    "we would like to repeatedly apply this model to generate new music! Thus, the model loss (and accuracy)\n",
    "are actually poor measures for how well a model would perform when generating music.\n",
    "\n",
    "Since loss/accuracy are poor measurements for model generalization, we will not set aside a test set.\n",
    "Instead, we will need a human (yes, you!) to judge how well our model is doing.\n",
    "We therefore won't concern ourselves too much with having a \n",
    "well split training/validation/test set where the test set is \"uncontaminated\" and distinct\n",
    "from the training set.\n",
    "\n",
    "We will still hold out a few pieces as part of our validation set. However,\n",
    "keep in mind that validation loss/accuracy may not be good indicators of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-particular",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_for_files(files):\n",
    "    Xs, ts = [], []\n",
    "    for file in files:\n",
    "        notes = get_midi_file_notes(file)\n",
    "        D = gen_input_output(notes)\n",
    "        X, t = get_X_t(D)\n",
    "        Xs.append(X)\n",
    "        ts.append(t)\n",
    "    X = np.concatenate(Xs, axis=0)\n",
    "    t = np.concatenate(ts, axis=0)\n",
    "    return X, t\n",
    "\n",
    "import glob\n",
    "files = [file for file in glob.glob('data/chopin/*_simplified.mid')]\n",
    "X_train, t_train = generate_data_for_files(files[:30])\n",
    "X_valid, t_valid = generate_data_for_files(files[30:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-arnold",
   "metadata": {},
   "source": [
    "**Task**: Train the model on this data set. This code may take several minutes to run.\n",
    "Again, the validation loss is, unfortunately, a poor measure of the quality of music generated. \n",
    "So we should not read too much into the validation loss too much.\n",
    "Instead, we will need to use other methods (e.g. human evaluation) to evaluate music quality\n",
    "and assess under/overfitting.\n",
    "\n",
    "Training for ~30 epochs may take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-medicare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code!\n",
    "model = MLPModel()\n",
    "train_sgd(model, alpha=0.1, X_train=X_train, t_train=t_train, X_valid=X_valid, t_valid=t_valid, batch_size=100, n_epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-number",
   "metadata": {},
   "source": [
    "**Task**: Now that we have a trained model, we can use your function \n",
    "`generate_piece` from earlier to generate a new piece of music\n",
    "using our model, one note at a time.\n",
    "\n",
    "Run the below code to generate a piece of music, starting from the first 20\n",
    "notes from notes_chpnop23.\n",
    "Generate `CONTEXT_LENGTH` number of new notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-covering",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = notes_chpnop23[:CONTEXT_LENGTH]\n",
    "\n",
    "notes = None # TODO\n",
    "generate_midi(notes, 'chpnop23_comp.mid')\n",
    "play_midi('chpnop23_comp.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-musician",
   "metadata": {},
   "source": [
    "**Optional Task**: Try some other seeds, and see what music you can generate with this model!\n",
    "We included music from a different composer (Debussy) in the data file. You can also try\n",
    "to build a model with Debussy's music as training data, and see how that model differs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-internship",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hindu-saturday",
   "metadata": {},
   "source": [
    "## Part 6. Limitations\n",
    "\n",
    "**Graded Task**:\n",
    "Your model may produce a few musical-sounding notes to continue your piece.\n",
    "However, if we set `max_len` large enough,\n",
    "sooner or later your model will likely produce the same sequence of\n",
    "notes over and over again.  Why do you think is the case? How is this\n",
    "behaviour related\n",
    "to the limitation of the model architecture? Recall that we are using\n",
    "a fixed number of previous notes to predict the next note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-brooks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-institute",
   "metadata": {},
   "source": [
    "In practice, practitioners shy away from using models like this. In CSC413, we will explore more advanced models such as Recurrent Neural Networks (RNNs) and Transformers, which are more powerful for handling such tasks."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
